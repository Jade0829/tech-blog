---
layout:     post
title:      "Lustre Changelog DR"
date:       2025-11-28
author:     김 재환 (jhkim@gluesys.com)
categories: blog
tags:       [Lustre, Changelog, DR, rsync, sync ]
cover:      ""
main:       ""
---

## 인사말

  이전 블로그 Lustre_FID_1[^1]과 Lustre_FID_2[^2]를 통해 Lustre 파일시스템에서 파일 생성 시 내부 동작 방식을 확인했습니다. 특히 Lustre가 파일을 고유한 FID(File Identifier)로 관리하는 방식을 살펴보면서, Lustre 파일시스템의 내부 동작 원리를 이해하셨을 것입니다.

  이번 블로그에서는 Lustre 파일시스템에서 파일 생성, 수정, 삭제와 같은 모든 이벤트를 기록하는 changelog[^3]와 이를 활용한 글루시스의 DR(Disaster Recovery) 솔루션을 소개하려고 합니다.

  올해 국가정보자원관리원에서 발생한 데이터 센터 화재와 같은 재난 상황에서도 시스템이 정상적으로 동작하려면 데이터 손실 없이 효과적인 백업 및 복구 전략이 필수적입니다. 재해 복구 계획에서 RPO[^4]는 가장 중요한 지표 중 하나로, RPO가 짧을수록 재난 발생 시 더 많은 데이터를 보호할 수 있어 비즈니스 연속성을 보장할 수 있습니다. 특히 Lustre와 같은 분산 파일시스템에서는 전체 데이터를 주기적으로 동기화하는 전통적인 방식보다, 변경된 부분만 효율적으로 추적하고 복제할 수 있는 방법이 중요합니다. 이를 통해 RPO를 최소화하고 실시간에 가까운 데이터 보호를 실현할 수 있습니다.



## 기존 rsync 방식의 문제점
  전통적인 DR 구현 방식으로는 rsync를 활용한 전체 스캔 기반 동기화가 널리 사용됩니다. 이 방식은 전체 파일시스템을 주기적으로 스캔하여 변경된 파일을 찾아 동기화하는 방식으로, 구현이 간단하고 널리 사용되지만 대규모 Lustre 파일시스템에서는 다음과 같은 한계점이 있습니다.

  rsync 기반 동기화는 SSH를 직접 사용하거나 sshd 데몬을 통해 실행할 수 있습니다. 두 방식 모두 전체 파일시스템을 스캔해야 하는 근본적인 한계를 가지고 있어, 다음과 같은 문제점이 있습니다:

| 구분 | SSH를 통한 rsync 방식 | sshd 데몬을 통한 rsync 방식 |
|------|---------------------|---------------------------|
| **장점** | • 구현이 간단하고 널리 사용되는 방식<br>• SSH의 암호화 기능을 활용한 안전한 전송<br>• 별도의 서버 프로세스 불필요 | • SSH 연결 재사용으로 오버헤드 감소 가능<br>• 중앙 집중식 관리 가능 |
| **단점** | • 전체 파일시스템 스캔으로 인한 긴 처리 시간<br>• 대규모 파일시스템에서 스캔 시간이 수 시간에서 수십 시간 소요<br>• 네트워크 대역폭을 비효율적으로 사용 (변경되지 않은 파일도 확인)<br>• 스캔 중 발생한 변경 사항은 다음 스캔까지 반영되지 않음 | • 여전히 전체 파일시스템 스캔 필요<br>• 스캔 시간이 파일시스템 크기에 비례하여 증가<br>• 실시간 동기화 불가능<br>• RPO[^4]가 스캔 주기에 의존 |

  두 방식 모두 파일시스템 크기에 비례하여 스캔 시간이 증가하며, 대규모 Lustre 파일시스템에서는 수십 시간이 소요될 수 있습니다. 또한 스캔 주기에 의존하기 때문에 RPO[^4]를 최소화하기 어렵고, 실시간 동기화가 불가능합니다. 이러한 한계점들로 인해 대규모 파일시스템 환경에서는 실시간에 가까운 DR을 구현하기 어렵습니다.



## 글루시스 DR 솔루션의 장점

  글루시스 DR 솔루션은 Lustre Changelog를 활용하여 전체 파일시스템을 스캔하는 기존 rsync 방식의 문제점들을 해결합니다:


### 효율성
- **네트워크 대역폭 절감**: 실제 변경된 데이터만 전송하여 불필요한 네트워크 트래픽을 최소화
- **처리 시간 단축**: 전체 스캔이 불필요하며, 변경된 파일만 식별하여 처리하므로 대규모 파일시스템에서도 빠른 동기화 가능


### 실시간성
- **이벤트 발생 즉시 처리**: 파일 변경 이벤트가 발생하는 즉시 동기화를 시작하여 RPO[^4]를 최소화
- **지속적인 모니터링**: 스캔 주기에 의존하지 않고 지속적으로 모니터링하여 실시간 동기화 실현


### 확장성
- **파일시스템 크기에 관계없이 일정한 처리 시간**: 변경된 파일 수에만 의존하므로 파일시스템 크기가 커져도 일정한 처리 시간 유지
- **MDT별 독립 처리로 병렬 처리 가능**: 여러 MDT의 이벤트를 병렬로 처리하여 전체 처리 시간 단축


### 정확성
- **Changelog Index 추적으로 중복/누락 방지**: 각 이벤트의 순차적 Index를 추적하여 동일한 변경 사항을 중복 처리하거나 누락하는 일이 없음
- **모든 변경 사항을 순차적으로 처리**: 이벤트 발생 순서대로 처리하여 일관성 보장

### 활용 시나리오

  이 솔루션은 다음과 같은 시나리오에서 효과적으로 활용할 수 있습니다:

- **데이터 센터 간 백업**: 주요 데이터 센터의 변경 사항을 백업 데이터 센터에 실시간으로 복제하여 재해 발생 시 빠른 복구 지원
- **재해 복구**: 재난 발생 시 최신 데이터까지 포함하여 빠른 복구 지원
- **지역별 복제**: 지리적으로 분산된 사이트 간 데이터 동기화로 지역별 서비스 제공
- **개발/운영 환경 동기화**: 운영 환경의 변경 사항을 개발 환경에 반영하여 테스트 환경 구축

  글루시스의 Lustre DR 솔루션은 이러한 기능들을 통해 대규모 Lustre 파일시스템 환경에서 안정적이고 효율적인 재해 복구를 지원합니다.



## Lustre Changelog

  Lustre Changelog는 Lustre 파일시스템에서 발생하는 모든 메타데이터 변경 사항을 기록하는 기능입니다. 파일 생성, 수정, 삭제, 권한 변경, 디렉토리 구조 변경 등과 같은 이벤트들이 시간 순서대로 기록되며, 이를 통해 파일시스템의 변경 이력을 추적할 수 있습니다.

![Alt text](/assets/changelog.png)

**Changelog 동작 흐름:**

① **Changelog 등록**: Lustre 관리자가 MDT에 `changelog_register`를 통해 Changelog를 등록합니다. 이 과정을 통해 해당 MDT에서 발생하는 메타데이터 변경 이벤트를 기록할 수 있도록 설정합니다.

② **클라이언트 I/O 발생**: 클라이언트가 파일 생성, 수정, 삭제 등의 I/O 작업을 Lustre 파일시스템에 요청합니다.

③ **Changelog 저장**: MDS(Metadata Server)가 클라이언트의 I/O 작업을 확인하고 처리한 후, 해당 이벤트를 Changelog로 MDT에 저장합니다. 각 이벤트는 타임스탬프, FID, 이벤트 타입 등의 정보와 함께 순차적으로 기록됩니다.

④ **Changelog 읽기 요청**: Changelog Reader(`lfs changelog` 명령어 또는 `llapi_changelog_recv()` API)가 Changelog 내용을 확인하기 위해 읽기 요청을 보냅니다.

⑤ **Changelog 조회**: MDS가 MDT에서 Changelog를 가져와 읽기 요청에 대응할 데이터를 준비합니다.

⑥ **Changelog 전달**: MDS가 조회한 Changelog 내용을 Changelog Reader에게 전달합니다. Reader는 이 정보를 활용하여 파일시스템 변경 이벤트를 실시간으로 추적하고 처리할 수 있습니다.


### Changelog의 동작 원리

  Changelog는 MDS(Metadata Server)에서 관리되며, 각 MDT(Metadata Target)별로 독립적으로 기록됩니다. 클라이언트에서 메타데이터 변경 작업이 발생하면, MDS는 해당 작업을 처리한 후 Changelog에 이벤트를 기록합니다. 

  Changelog는 내부적으로 순차적인 로그 파일 형태로 저장되며, 각 로그 엔트리는 다음과 같은 정보를 포함합니다:

- **타임스탬프**: 이벤트 발생 시간
- **FID**: 변경된 파일 또는 디렉토리의 FID(File Identifier)
- **이벤트 타입**: CREATE, UNLINK, RENAME, SETATTR 등의 작업 유형
- **부가 정보**: 작업과 관련된 추가 메타데이터

  Changelog는 비동기적으로 기록되기 때문에 일반적인 파일시스템 작업 성능에는 거의 영향을 주지 않습니다. 다만, 활성화된 이벤트 타입이 많을수록 디스크 사용량이 증가할 수 있으므로, 실제로 필요한 이벤트만 선택적으로 활성화하는 것이 좋습니다.


### Changelog 활성화 및 확인

  Changelog 기능을 사용하려면 먼저 MDS에서 Changelog를 활성화해야 합니다. Changelog는 기본적으로 비활성화되어 있으며, 다음과 같이 활성화할 수 있습니다:

```shell
# 1. Changelog 등록 (changelog_register)
lctl changelog_register <MDT_device>

# 2. Changelog 활성화 및 이벤트 타입 설정
lctl set_param mdd.*.changelog_mask="CREAT UNLINK RENAME SETATTR"

# Changelog 상태 확인
lctl get_param mdd.*.changelog_mask
```

  먼저 `changelog_register`를 통해 MDT에 Changelog를 등록한 후, `changelog_mask` 파라미터를 통해 기록할 이벤트 타입을 선택적으로 지정할 수 있습니다. 필요한 이벤트만 기록하도록 설정하면 디스크 사용량을 절약할 수 있습니다.


#### changelog_mask 이벤트 타입

`changelog_mask`에서 사용할 수 있는 주요 이벤트 타입은 다음과 같습니다:

**파일 및 디렉토리 작업:**
- **CREAT**: 파일 또는 디렉토리 생성
- **UNLINK**: 파일 또는 디렉토리 삭제
- **MKDIR**: 디렉토리 생성
- **RMDIR**: 디렉토리 삭제
- **RENAME**: 파일 또는 디렉토리 이름 변경

**파일 속성 및 메타데이터:**
- **SETATTR**: 파일 속성 변경 (권한, 소유자, 그룹 등)
- **SATTR**: 파일 속성 설정 (SETATTR과 유사하지만 세부 동작이 다름)
- **XATTR**: 확장 속성(Extended Attribute) 설정 또는 변경
- **TRUNCATE**: 파일 크기 변경

**파일 접근:**
- **OPEN**: 파일 열기
- **CLOSE**: 파일 닫기

**HSM 관련:**
- **HSM**: HSM(Hierarchical Storage Management) 관련 작업 (파일 아카이빙, 복원 등)

**기타:**
- **MARK**: 마커 이벤트 (특정 시점을 표시하기 위한 이벤트)
- **ATIME**: 접근 시간 변경 (기본적으로 비활성화)
- **GXATR**: 확장 속성 접근 (기본적으로 비활성화)
- **NOPEN**: 파일 열기 거부 (기본적으로 비활성화)

  일부 이벤트 타입(ATIME, GXATR, NOPEN 등)은 기본적으로 비활성화되어 있으며, 이러한 이벤트를 기록하려면 명시적으로 mask에 포함시켜야 합니다. 다만, 이러한 이벤트는 빈번하게 발생할 수 있어 디스크 사용량이 크게 증가할 수 있으므로 신중하게 선택해야 합니다.


### Changelog 읽기

  Changelog를 읽기 위해서는 `lfs changelog` 명령어를 사용합니다:

```shell
# 특정 MDT의 Changelog 읽기
lfs changelog <MDT_device>

# 특정 시점 이후의 Changelog 읽기
lfs changelog <MDT_device> <start_record>

# 실시간으로 Changelog 모니터링
lfs changelog <MDT_device> --follow
```

  Changelog는 순차적인 레코드 번호를 가지며, 특정 레코드 번호부터 읽어올 수 있습니다. 각 레코드는 다음과 같은 형식으로 출력됩니다:

```
12345 08/01/2025 14:30:25 CREAT [0x200000007:0x1:0x0] /lustre/test/file.txt
12346 08/01/2025 14:30:26 MODIFY [0x200000007:0x1:0x1] /lustre/test/file.txt
12347 08/01/2025 14:30:27 UNLINK [0x200000007:0x1:0x1] /lustre/test/file.txt
```

  각 레코드는 레코드 번호, 타임스탬프, 이벤트 타입, FID, 그리고 파일 경로(가능한 경우)를 포함합니다. 이 정보를 활용하여 특정 시점 이후의 변경 사항만 추출하거나, 특정 파일의 변경 이력을 추적할 수 있습니다.


### Changelog의 활용

  Changelog의 가장 큰 장점은 파일시스템의 전체 스캔 없이 변경된 파일만 식별할 수 있다는 점입니다. 전통적인 `rsync`와 같은 도구는 전체 파일시스템을 스캔하여 변경 사항을 찾아야 하지만, Changelog를 활용하면 최근 변경된 파일만 효율적으로 처리할 수 있습니다.

  이러한 특성으로 인해 Changelog는 다음과 같은 용도로 활용됩니다:

- **증분 백업**: 변경된 파일만 선택적으로 백업
- **DR(Disaster Recovery)**: 원격 사이트로 변경 사항만 동기화
- **감사(Audit)**: 파일시스템 변경 이력 추적
- **HSM**: 자주 사용되지 않는 파일을 계층적 스토리지로 마이그레이션







## 글루시스 DR 솔루션

  앞서 설명한 Changelog를 활용하여 구축한 글루시스의 Lustre DR 솔루션은 실시간으로 파일시스템 변경 사항을 원격 사이트에 동기화하는 시스템입니다. 전통적인 전체 스캔 기반 동기화 방식과 달리, 변경된 파일만 효율적으로 추적하고 복제하여 네트워크 대역폭과 처리 시간을 크게 절감할 수 있습니다.

### 시스템 구성

  글루시스 DR 솔루션은 다음과 같은 기술 스택으로 구성됩니다:

- **모니터링**: C 언어로 구현된 모니터링 컴포넌트가 Lustre API(`llapi_changelog_recv()`)를 직접 호출하여 이벤트 수집. C 언어를 선택한 이유는 Lustre API와의 직접적인 통합이 필요하고, 실시간 성능이 중요한 모니터링 작업에 적합하기 때문입니다.

- **이벤트 큐**: Redis Stream[^6]을 사용하여 이벤트를 비동기적으로 전달.

- **원격 통신**: gRPC를 사용하여 타겟 서버와 통신. gRPC는 HTTP/2 기반의 고성능 RPC 프레임워크로, 타입 안전성과 효율적인 직렬화를 제공합니다. 파일 메타데이터 작업에 최적화되어 있습니다.

- **파일 동기화**: SSH 기반 rsync를 사용하여 안전하고 효율적인 파일 전송. rsync는 증분 동기화에 최적화된 도구로, 변경된 부분만 전송하여 네트워크 대역폭을 절약합니다. SSH를 통해 암호화된 안전한 전송을 보장합니다.

- **설정 관리**: JSON 형식의 설정 파일. JSON은 가독성이 좋고 다양한 프로그래밍 언어에서 쉽게 파싱할 수 있어 설정 관리에 적합합니다.

### 시스템 아키텍처

![Alt text](/assets/changelog_DR.png)

  글루시스 DR 솔루션은 세 가지 주요 컴포넌트로 구성됩니다:

1. **모니터링 컴포넌트**: Lustre Changelog를 실시간으로 모니터링하고 이벤트를 수집하는 모니터링 데몬
2. **소스 서버 컴포넌트**: 소스 서버에서 실행되며, 수집된 이벤트를 처리하고 동기화 작업을 수행하는 서버
3. **타겟 서버 컴포넌트**: 타겟 서버에서 실행되며, 원격에서 전송된 파일 작업 요청을 처리하는 서버

  이 세 컴포넌트는 Redis Stream[^6]을 통해 이벤트를 전달하고, gRPC[^7]를 통해 원격 파일 작업을 수행합니다.


#### 컴포넌트별 상세 기능

**모니터링 컴포넌트**
- MDT가 여러 개인 경우 각 MDT별로 독립적인 프로세스로 동작
- 메인 쓰레드와 두 개의 서브 쓰레드로 구성된 멀티 쓰레드 구조
  - 메인 쓰레드: MDT 모니터링 및 리소스 관리
  - 모니터링 쓰레드: Lustre changelog 이벤트 수집
  - 필터 쓰레드: 이벤트 필터링 및 Redis 저장
- 하이브리드 Redis Stream 저장 (MDT별 스트림 + 통합 스트림)
- 이벤트 타입별 분류 (create_modify, rename_delete)

**소스 서버 컴포넌트**
- Redis Stream에서 이벤트를 읽어 처리
- MDT별 Changelog Index 관리 및 추적


**타겟 서버 컴포넌트**
- gRPC 서버로 원격 파일 작업 처리
- 소스 서버와 타겟 서버 간 경로 자동 변환
- 실패 이벤트 상세 분석 및 재시도 가능 여부 판단


### 동작 원리


#### 1. 이벤트 수집 단계

  모니터링 컴포넌트는 Lustre의 `llapi_changelog_recv()` API를 사용하여 파일시스템 변경 이벤트를 실시간으로 수집합니다. 각 MDT(Metadata Target)별로 독립적인 프로세스로 동작하며, 수집된 이벤트는 Redis Stream[^6]에 저장됩니다.

  이 과정에서 불필요한 파일(예: Vim 임시 파일, 백업 파일 등)은 설정 파일의 `excludePatterns`를 통해 필터링되어 동기화 대상에서 제외됩니다. 또한 시스템 재시작 시 중복 처리를 방지하기 위해 Redis에서 마지막 처리된 Changelog Index를 로드하여 해당 지점부터 이벤트를 읽기 시작합니다.

**왜 Redis Stream인가??**

  실시간 DR 솔루션에서 이벤트 큐로 Redis Stream을 선택한 이유는 다음과 같습니다:

1. **순서 보장의 중요성**: 실시간 동기화에서는 이벤트가 발생한 순서대로 처리하는 것이 매우 중요합니다. 예를 들어, 파일을 생성한 후 수정하고 삭제하는 경우, 이 순서가 바뀌면 데이터 불일치가 발생할 수 있습니다. Redis Stream은 시간 순서대로 정렬된 로그 구조로, 이벤트의 순차적 처리를 보장합니다.

2. **빈번한 이벤트 처리**: 대규모 Lustre 파일시스템에서는 초당 수천 개의 파일 변경 이벤트가 발생할 수 있습니다. Redis Stream은 메모리 기반의 고성능 데이터 구조로, 이러한 빈번한 이벤트를 빠르게 저장하고 처리할 수 있습니다.

3. **대용량 데이터 저장**: 파일시스템 변경 이벤트는 지속적으로 누적되며, 동기화 처리 속도가 일시적으로 느려질 경우 대량의 이벤트가 쌓일 수 있습니다. Redis Stream은 수백만 개의 엔트리를 효율적으로 저장하고 관리할 수 있어, 피크 시간대의 이벤트 폭주에도 안정적으로 대응할 수 있습니다.

4. **Consumer Group을 통한 안전한 처리**: Redis Stream의 Consumer Group 기능을 통해 여러 소비자가 동일한 스트림을 안전하게 읽을 수 있습니다. 이를 통해 동일한 이벤트를 중복 처리하거나 누락하는 일 없이, 여러 소비자 간에 작업을 분산할 수 있습니다.

5. **비동기 처리와 버퍼링**: 모니터링 컴포넌트가 이벤트를 수집하는 속도와 소스 서버 컴포넌트가 처리하는 속도가 다를 수 있습니다. Redis Stream은 이러한 속도 차이를 버퍼링하여, 이벤트 손실 없이 안정적인 비동기 처리를 가능하게 합니다.

**Redis Stream 구조**

  수집된 이벤트는 Redis Stream에 다음과 같은 구조로 저장됩니다:

**전체 구조 요약**

```
• event: 이벤트 타입 (CREATE, MODIFY, RENAME, DELETE, RMDIR)
• path: 파일/디렉토리 절대 경로 (RENAME 시 원본 경로)
• to_path: RENAME 이벤트 시 변경될 경로
• mdt: MDT 이름
• index: Lustre changelog index

Redis
│
├── Streams (Redis Stream)
│   ├── changelog:source1:create_modify
│   │   └── Entry: {event, path, mdt, index}
│   │
│   ├── changelog:source1:rename_delete
│   │   └── Entry: {event, path, to_path, mdt, index}
│   │
│   ├── changelog:MDT0000:source1
│   │   └── Entry: {event, path, mdt, index}
│   │
│   ├── changelog:source1:resync
│   │   └── Entry: {event, path, mdt, index}
│   │
│   └── changelog:source1:rename_delete_resync
│       └── Entry: {event, path, to_path, mdt, index}
│
├── Checkpoints (String)
│   ├── last_processed_id:source1:create_modify
│   │   └── Value: "1234567890124-0" (마지막 처리된 Stream Entry ID)
│   │
│   └── last_processed_id:source1:rename_delete
│       └── Value: "1234567890126-0" (마지막 처리된 Stream Entry ID)
│
└── Indexes (String)
    ├── changelog:MDT0000
    │   └── Value: "12350" (MDT0000에서 처리된 최대 changelog index)
    │
    └── changelog:MDT0001
        └── Value: "12346" (MDT0001에서 처리된 최대 changelog index)
```
**1. MDT별 Stream 구조**

```
┌─────────────────────────────────────────────────────────────┐
│ Stream Key: changelog:MDT0000:source1                       │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Entry ID: 1234567890123-0                                  │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ Field      │ Value                                  │    │
│  ├─────────────────────────────────────────────────────┤    │
│  │ event      │ "CREATE"                               │    │
│  │ path       │ "/lustre/file.txt"                     │    │
│  │ mdt        │ "MDT0000"                              │    │
│  │ index      │ "12345"                                │    │
│  └─────────────────────────────────────────────────────┘    │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**2. create_modify Stream 구조**

```
┌─────────────────────────────────────────────────────────────┐
│ Stream Key: changelog:source1:create_modify                 │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Entry ID: 1234567890123-0                                  │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ Field      │ Value                                  │    │
│  ├─────────────────────────────────────────────────────┤    │
│  │ event      │ "CREATE" / "MODIFY" / "MKDIR"          │    │
│  │ path       │ "/lustre/file.txt"                     │    │
│  │ mdt        │ "MDT0000"                              │    │
│  │ index      │ "12345"                                │    │
│  └─────────────────────────────────────────────────────┘    │
│                                                             │
│  Entry ID: 1234567890124-0                                  │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ Field      │ Value                                  │    │
│  ├─────────────────────────────────────────────────────┤    │
│  │ event      │ "MODIFY"                               │    │
│  │ path       │ "/lustre/file2.txt"                    │    │
│  │ mdt        │ "MDT0001"                              │    │
│  │ index      │ "12346"                                │    │
│  └─────────────────────────────────────────────────────┘    │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**3. rename_delete Stream 구조**

```
┌─────────────────────────────────────────────────────────────┐
│ Stream Key: changelog:source1:rename_delete                 │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Entry ID: 1234567890125-0                                  │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ Field      │ Value                                  │    │
│  ├─────────────────────────────────────────────────────┤    │
│  │ event      │ "RENAME"                               │    │
│  │ path       │ "/lustre/old.txt"                      │    │
│  │ to_path    │ "/lustre/new.txt"                      │    │
│  │ mdt        │ "MDT0000"                              │    │
│  │ index      │ "12347"                                │    │
│  └─────────────────────────────────────────────────────┘    │
│                                                             │
│  Entry ID: 1234567890126-0                                  │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ Field      │ Value                                  │    │
│  ├─────────────────────────────────────────────────────┤    │
│  │ event      │ "DELETE"                               │    │
│  │ path       │ "/lustre/file.txt"                     │    │
│  │ mdt        │ "MDT0000"                              │    │
│  │ index      │ "12348"                                │    │
│  └─────────────────────────────────────────────────────┘    │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**4. 재시도 Stream 구조 (resync)**

```
┌─────────────────────────────────────────────────────────────┐
│ Stream Key: changelog:source1:resync                        │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Entry ID: 1234567890127-0                                  │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ Field      │ Value                                  │    │
│  ├─────────────────────────────────────────────────────┤    │
│  │ event      │ "CREATE"                               │    │
│  │ path       │ "/lustre/retry_file.txt"               │    │
│  │ mdt        │ "MDT0000"                              │    │
│  │ index      │ "12349"                                │    │
│  └─────────────────────────────────────────────────────┘    │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**5. 재시도 Stream 구조 (rename_delete_resync)**

```
┌─────────────────────────────────────────────────────────────┐
│ Stream Key: changelog:source1:rename_delete_resync          │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  Entry ID: 1234567890128-0                                  │
│  ┌─────────────────────────────────────────────────────┐    │
│  │ Field      │ Value                                  │    │
│  ├─────────────────────────────────────────────────────┤    │
│  │ event      │ "RENAME"                               │    │
│  │ path       │ "/lustre/old_retry.txt"                │    │
│  │ to_path    │ "/lustre/new_retry.txt"                │    │
│  │ mdt        │ "MDT0000"                              │    │
│  │ index      │ "12350"                                │    │
│  └─────────────────────────────────────────────────────┘    │
│                                                             │
└─────────────────────────────────────────────────────────────┘
```

**6. 체크포인트 구조**

```
┌─────────────────────────────────────────────────────────────┐
│ Key: last_processed_id:source1:create_modify                │
├─────────────────────────────────────────────────────────────┤
│ Type: String                                                │
│ Value: "1234567890124-0"                                    │
│ 설명: 마지막으로 처리된 Stream Entry ID                      │
└─────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────┐
│ Key: last_processed_id:source1:rename_delete                │
├─────────────────────────────────────────────────────────────┤
│ Type: String                                                │
│ Value: "1234567890126-0"                                    │
│ 설명: 마지막으로 처리된 Stream Entry ID                      │
└─────────────────────────────────────────────────────────────┘
```

**7. MDT Index 구조**

```
┌─────────────────────────────────────────────────────────────┐
│ Key: changelog:MDT0000                                      │
├─────────────────────────────────────────────────────────────┤
│ Type: String                                                │
│ Value: "12350"                                              │
│ 설명: MDT0000에서 처리된 최대 changelog index                │
└─────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────┐
│ Key: changelog:MDT0001                                      │
├─────────────────────────────────────────────────────────────┤
│ Type: String                                                │
│ Value: "12346"                                              │
│ 설명: MDT0001에서 처리된 최대 changelog index                │
└─────────────────────────────────────────────────────────────┘
```






#### 2. 동기화 처리 단계

  소스 서버 컴포넌트는 Redis Stream에서 이벤트를 읽어 이벤트 타입에 따라 적절한 동기화 방법을 선택하여 처리합니다. 동기화는 이벤트 타입에 따라 두 가지 방식으로 나뉩니다:

**2.1 rsync를 통한 동기화 (CREATE/MODIFY 이벤트)**

  파일 생성이나 수정 이벤트의 경우, 대용량 데이터 전송에 최적화된 `rsync`를 사용합니다. 소스 서버 컴포넌트는 변경된 파일 목록을 수집하고, SSH를 통해 타겟 서버로 파일을 복사합니다. 이 방식은 파일의 실제 데이터를 효율적으로 전송하는 데 적합합니다.

  동기화 과정은 다음과 같이 진행됩니다:

1. **이벤트 수집**: Redis Stream에서 CREATE/MODIFY 이벤트를 읽어 파일 목록 생성
2. **파일 존재 확인**: 각 파일의 존재 여부를 사전 확인하여 존재하지 않는 파일은 제외
3. **임시 파일 생성**: 존재하는 파일들의 상대 경로를 임시 파일에 기록
4. **rsync 실행**: `--ignore-missing-args` 옵션을 사용하여 안전하게 파일 전송
5. **결과 확인**: rsync 실행 후 파일 존재 여부를 재확인하여 삭제된 파일은 크기 비교에서 제외
6. **Index 업데이트**: 동기화 완료 후 Changelog Index 업데이트



**2.2 gRPC를 통한 동기화 (RENAME/DELETE 이벤트)**

  파일명 변경이나 삭제 이벤트의 경우, 메타데이터만 처리하면 되므로 gRPC를 통해 타겟 서버 컴포넌트에 직접 요청합니다. 타겟 서버 컴포넌트는 gRPC 요청을 받아 파일 이동, 삭제 등의 작업을 수행하며, 소스 서버와 타겟 서버 간의 경로 차이를 자동으로 변환하여 올바른 위치에 동기화합니다.

  gRPC를 통한 동기화 과정은 다음과 같습니다:

1. **이벤트 수집**: Redis Stream에서 RENAME/DELETE 이벤트를 읽어 요청 목록 생성
2. **gRPC 요청 전송**: 타겟 서버의 `RmvSync` API를 호출하여 파일 작업 요청
3. **경로 변환**: 소스 서버 경로를 타겟 서버 경로로 자동 변환
4. **파일 작업 실행**: 타겟 서버에서 파일 이동 또는 삭제 수행
5. **결과 반환**: 성공/실패 여부와 상세 오류 정보를 소스 서버에 반환
6. **Index 업데이트**: 성공한 작업에 대해서만 Changelog Index 업데이트


#### 3. Changelog Index 관리

  시스템 재시작 시 중복 처리나 누락을 방지하기 위해 Changelog Index를 추적하고 관리합니다. 글루시스 DR 솔루션은 두 가지 레벨의 인덱스 관리를 통해 예상치 못한 상황에서도 안정적으로 동작할 수 있도록 설계되었습니다.

  **MDT별 인덱스 관리**

  각 MDT(Metadata Target)별로 독립적인 Changelog Index를 관리합니다. Redis에는 `changelog:MDT0000`, `changelog:MDT0001` 형식의 키로 각 MDT에서 처리된 최대 changelog index가 저장됩니다. 

  모니터링 컴포넌트는 시작 시 각 MDT별로 저장된 마지막 Index를 로드하여 해당 지점부터 changelog를 읽기 시작합니다. 예를 들어, MDT0000의 마지막 Index가 12350이면, 12351번부터 changelog를 읽어 이벤트를 수집합니다. 이를 통해 시스템이 예상치 못하게 종료되어도 각 MDT별로 정확한 지점부터 이벤트 수집을 재개할 수 있습니다.

  **동기화 인덱스 관리 (체크포인트)**

  소스 서버 컴포넌트는 Redis Stream에서 이벤트를 읽어 처리할 때, 마지막으로 처리된 Stream Entry ID를 체크포인트로 저장합니다. `last_processed_id:source1:create_modify`, `last_processed_id:source1:rename_delete` 형식의 키로 각 스트림별 마지막 처리 위치를 추적합니다.

  동기화 작업이 완료될 때마다 체크포인트가 업데이트되며, 다음 동기화 작업 시 이 체크포인트 이후의 이벤트만 읽어 처리합니다. 예를 들어, `last_processed_id:source1:create_modify`의 값이 `1234567890124-0`이면, 해당 Entry ID 이후의 이벤트만 읽어 중복 처리를 방지합니다.

  **예상치 못한 종료 시 복구 메커니즘**

  프로그램이 예상치 못한 상황(시스템 크래시, 네트워크 장애, 프로세스 강제 종료 등)에서 종료되어도, 저장된 인덱스 정보를 활용하여 이전 작업을 이어서 수행할 수 있습니다.

  - **모니터링 컴포넌트 재시작**: MDT별 인덱스를 로드하여 마지막 처리된 changelog index 이후의 이벤트만 수집합니다. 이미 수집되어 Redis Stream에 저장된 이벤트는 중복 저장되지 않습니다.

  - **소스 서버 컴포넌트 재시작**: 체크포인트를 로드하여 마지막 처리된 Stream Entry ID 이후의 이벤트만 읽어 처리합니다. 동기화가 완료되지 않은 이벤트는 자동으로 재처리됩니다.

  - **타겟 서버 컴포넌트 재시작**: gRPC 서버가 재시작되어도 소스 서버에서 재시도 요청을 보내면 정상적으로 처리할 수 있습니다.

  이러한 이중 인덱스 관리 구조(MDT별 인덱스 + 동기화 체크포인트)를 통해, 시스템이 어떤 상황에서 중단되더라도 정확한 지점부터 동기화를 재개할 수 있습니다.

#### 4. 오류 처리 및 재시도 메커니즘

  동기화 과정에서 발생하는 오류를 효율적으로 처리하기 위해 재시도 메커니즘을 구현했습니다. rsync 실행 시 실패한 파일 목록을 분석하여, 재시도 가능한 오류와 재시도 불가능한 오류를 구분합니다.

  **재시도 스트림을 통한 누락 방지**

  동기화 과정에서 실패한 이벤트는 재시도 가능 여부를 판단하여 적절히 처리됩니다. 재시도 가능한 오류(일시적인 네트워크 오류, 파일 잠금, 타임아웃 등)는 `changelog:source1:resync` 또는 `changelog:source1:rename_delete_resync` 스트림에 저장됩니다.

  다음 동기화 작업 시 일반 스트림과 재시도 스트림의 이벤트를 함께 처리하여, 일시적인 문제로 실패한 파일들이 자동으로 복구됩니다. 재시도 스트림의 이벤트도 동일한 체크포인트 메커니즘을 통해 관리되므로, 재시도 과정에서도 중복 처리가 발생하지 않습니다.

  **재시도 불가능한 오류 처리**

  재시도 불가능한 오류(예: 파일이 존재하지 않음, 권한 오류 등)는 상세한 오류 정보와 함께 로그에 기록되어 관리자가 수동으로 처리할 수 있도록 합니다. 각 실패 이벤트에는 에러 메시지, 에러 코드, 재시도 가능 여부 등의 정보가 포함되어 있어 문제 진단이 용이합니다.

  이러한 재시도 메커니즘을 통해, 일시적인 문제로 인한 동기화 실패도 자동으로 복구되어 데이터 누락 없이 안정적으로 동기화를 수행할 수 있습니다.


### 주요 특징


#### 효율적인 증분 동기화

  전체 파일시스템을 스캔하는 대신, Changelog를 통해 변경된 파일만 식별하여 동기화합니다. 이를 통해 대규모 파일시스템에서도 빠른 동기화가 가능하며, 네트워크 대역폭을 효율적으로 활용할 수 있습니다.


#### 실시간 동기화

  이벤트 발생 즉시 처리되므로, 재해 발생 시 최신 데이터까지 복구할 수 있습니다. 또한 Changelog Index를 추적하여 시스템 재시작 후에도 중복 처리나 누락 없이 동기화를 계속할 수 있습니다.


#### 안정적인 오류 처리

  동기화 실패 시 상세한 오류 정보를 기록하고, 재시도 가능한 작업은 자동으로 재시도 큐에 추가하여 처리합니다. 실패한 파일 목록을 추적하여 관리자가 수동으로 처리할 수 있도록 지원합니다.


#### 파일 필터링 시스템

  설정 파일의 `excludePatterns`를 통해 불필요한 파일(임시 파일, 백업 파일 등)을 동기화 대상에서 제외할 수 있습니다. 기본적으로 Vim 임시 파일(.swp, .swo, .swx)과 백업 파일(~)이 제외됩니다.


### 이벤트 타입별 처리 방식

  글루시스 DR 솔루션은 이벤트 타입에 따라 최적화된 처리 방식을 사용합니다:

| 이벤트 타입 | 처리 방식 | 사용 도구 | 설명 |
|------------|----------|----------|------|
| CREATE | rsync | rsync | 새로 생성된 파일을 타겟 서버로 복사 (HLINK, SLINK 포함) |
| MODIFY | rsync | rsync | 수정된 파일의 변경 사항을 동기화 (MTIME, TRUNC, SATTR 포함) |
| RENAME | gRPC | moveFile | 파일명 변경을 타겟 서버에서 직접 처리 |
| DELETE | gRPC | deleteFile | 파일 삭제를 타겟 서버에서 직접 처리 |
| RMDIR | gRPC | deleteFile | 디렉토리 삭제를 타겟 서버에서 직접 처리 |

**MODIFY 이벤트 세부 타입:**
- **MTIME**: 파일 수정 시간 변경
- **TRUNC**: 파일 크기 변경 (tfid를 사용하여 전체 경로 조회)
- **SATTR**: 파일 속성 변경 (tfid를 사용하여 전체 경로 조회)





### 테스트 결과

  아래 표는 재해 복구 솔루션에 대한 등급표입니다. 해당 표를 기준으로 글루시스 DR 솔루션의 RPO[^4]와 RTO[^5]를 평가하여 어떤 등급에 해당하는지 확인해보겠습니다.

| 구분 | Platinum | Gold | Silver | Bronze |
|------------|----------|----------|------|-------|
| 대상 업무 | 기업의 생산, 판매 및 영업활동에 직접적인 영향을 주는 업무 | 기업의 대고객 서비스에 영향을 주는 업무 | 기업의 내부 운영에 영향을 주는 업무 | 기업의 내부 업무 지원을 위한 개발, 테스트 업무 |
| RPO| 0에 근접 | 0에 근접 | < 2일 | < 2일 |
| RTO | < 3시간 | < 24시간 | < 7일 | < 30일 |
| 권장 거리 | 근거리 + 장거리 | 근거리, 장거리 | 근거리, 장거리 | 근거리, 장거리 |
| 권장 DR 형태 | <= 3DC | 2DC | 2DC | 2DC |
| 권장 DR 솔루션 | 디스크 복제 | 디스크 복제 | 소프트웨어 복제 | 소프트웨어 복제, 백업 |
| 업무 성능 저하 허용 여부 | 불가 | 불가 | 허용 | 허용 |

  아래 표는 글루시스 DR 솔루션의 테스트 결과입니다. 본 솔루션은 동기화 시 파일을 묶어서 처리하는 배치 처리 방식을 사용합니다. 표에서 동기화 평균 시간은 배치로 묶인 파일들의 동기화에 소요된 시간이며, 배치 대기 시간은 파일 변경을 감지한 시점부터 실제 동기화가 시작된 시점까지의 시간 차이를 의미합니다.

| 구분 | 파일 평균 사이즈 | 파일 수 | 처리 속도 | 동기화 평균 시간 ( 배치당 300개 파일 기준준 ) | 배치 대기 시간 |
|-----|--------|---------|--------|---------|-------|
| 일반 파일 | 55M | 10,000 | 412 MB/s | 39s | 19m40s |
| 잔파일 | 314K | 10,000 | 24.2 MB/s | 0.32s | 2m42s |

 테스트 결과를 분석해보면, 데이터는 실시간으로 동기화되며 일반 파일 기준으로 동기화 완료까지 약 20분이 소요됩니다. 전체 서비스 복구 시간은 기업의 내부 시스템 구성에 따라 달라질 수 있으나, 일반적으로 3시간 내지 24시간 이내에 복구가 가능할 것으로 판단됩니다. 따라서 RPO[^4]는 0에 근접하며, RTO는 최대 24시간 이내로 평가되어 본 솔루션은 Platinum 또는 Gold 등급에 해당한다고 볼 수 있습니다.



## 마치며

  이번 블로그에서는 Lustre 파일시스템의 DR(Disaster Recovery) 솔루션을 주제로, 전통적인 rsync 방식의 한계와 이를 극복하기 위한 Changelog 기반 DR 솔루션에 대해 알아보았습니다.

  먼저 전통적인 rsync 기반 동기화 방식의 문제점을 살펴보았습니다. SSH를 통한 방식과 sshd 데몬을 통한 방식 모두 전체 파일시스템을 스캔해야 하는 근본적인 문제를 가지고 있어, 대규모 파일시스템에서는 처리 시간이 수십 시간 소요되고 RPO를 최소화하기 어렵다는 한계가 있습니다.

  이러한 문제점들을 해결하기 위해 제시된 글루시스 DR 솔루션의 장점을 확인했습니다. Changelog를 활용함으로써 효율성, 실시간성, 확장성, 정확성 측면에서 전통적인 방식보다 우수한 성능을 제공할 수 있습니다.

  이어서 Changelog의 동작 원리와 활성화 방법, 그리고 다양한 이벤트 타입에 대해 살펴보았습니다. Changelog는 파일시스템의 전체 스캔 없이 변경된 파일만 효율적으로 추적할 수 있게 해주는 핵심 기능입니다. 비동기적으로 기록되기 때문에 파일시스템 성능에 미치는 영향이 최소화되며, 필요한 이벤트만 선택적으로 활성화하여 디스크 사용량을 관리할 수 있습니다.

  마지막으로 글루시스 DR 솔루션의 아키텍처와 동작 원리를 설명했습니다. 세 가지 주요 컴포넌트(모니터링, 소스 서버, 타겟 서버)가 Redis Stream과 gRPC를 통해 협력하여 실시간으로 파일시스템 변경 사항을 원격 사이트에 동기화하는 방식을 확인했습니다. 

  특히 주목할 만한 점은 이벤트 타입에 따라 rsync와 gRPC를 선택적으로 사용하는 이원화된 접근 방식입니다. 파일 생성/수정은 대용량 데이터 전송에 최적화된 rsync를 사용하고, 파일명 변경/삭제는 메타데이터만 처리하는 gRPC를 사용함으로써 네트워크 효율성과 처리 속도를 극대화합니다.

  또한 Changelog Index를 추적하여 시스템 재시작 후에도 중복 처리나 누락 없이 동기화를 계속할 수 있으며, 재시도 메커니즘을 통해 일시적인 오류로 실패한 파일들을 자동으로 복구할 수 있습니다. 이러한 기능들을 통해 전통적인 전체 스캔 방식의 한계를 극복하고, 대규모 파일시스템에서도 효율적이고 안정적인 DR을 실현할 수 있습니다.

  다음 시간에는 ZFS 파일시스템을 기반으로 한 DR 솔루션에 대해 소개하겠습니다. ZFS의 고유한 기능들(스냅샷, 복제 등)을 활용한 DR 솔루션이 Lustre와 어떤 차이점을 가지는지, 그리고 각각의 장단점은 무엇인지 알아보는 시간을 가져보겠습니다.

---

## 각주

[^1]: Lustre_FID_1 : https://tech.gluesys.com/blog/2025/03/13/Lustre_FID_1.html
&nbsp;
[^2]: Lustre_FID_2 : https://tech.gluesys.com/blog/2025/09/01/Lustre_FID_2.html
&nbsp;
[^3]: changelog : https://doc.lustre.org/lustre_manual.xhtml#lustre_changelogs
&nbsp;
[^4]: RPO(Recovery Point Objective) : 재해 복구에서 허용 가능한 최대 데이터 손실 시간 
&nbsp;
[^5]: RTO(Recovery Time Objective) : 업무의 복구 목표 시간
[^6]: Redis Stream : Redis 5.0에서 도입된 데이터 구조로, 시간 순서대로 정렬된 로그 형태의 메시지 큐 - https://redis.io/docs/data-types/streams/ 
&nbsp;
[^7]: gRPC : Google에서 개발한 고성능 오픈소스 RPC(Remote Procedure Call) 프레임워크 - https://grpc.io/ 
&nbsp;
